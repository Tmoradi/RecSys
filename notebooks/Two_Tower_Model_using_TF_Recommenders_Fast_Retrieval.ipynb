{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "JlqmdU4BiM_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q protobuf==3.19.6\n",
        "!pip install -q tensorflow==2.11.1 --no-deps\n",
        "!pip install -q tensorflow-recommenders=='v0.7.3' --no-deps\n",
        "!pip install -q tensorflow-datasets==3.2.0 --no-deps\n",
        "!pip install -q tensorflow-metadata==0.22.2 --no-deps\n",
        "!pip install -q scann\n",
        "!pip install -q dill==0.3.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BzXWs7oVSrh",
        "outputId": "0efb1e21-72b3-4e1a-fe10-969cc430fbaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "dHjp5kCeiQzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "zDNJK1E7iyje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ecommerce dataset\n",
        "df_ecommerce = pd.read_csv('ecommerce.csv') # Contains transactions\n",
        "df_products = pd.read_csv('products.csv')   # Contains products"
      ],
      "metadata": {
        "id": "odG6GaIX2Wco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataframe to tensors\n",
        "ds_ecommerce = tf.data.Dataset.from_tensor_slices(dict(df_ecommerce))\n",
        "ds_products = tf.data.Dataset.from_tensor_slices(dict(df_products))"
      ],
      "metadata": {
        "id": "HP4JrSmE2W2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select fields\n",
        "ds_ecommerce = ds_ecommerce.map(lambda x: {\n",
        "    'user_id': tf.strings.as_string(x['user_id']),\n",
        "    'product_id': tf.strings.as_string(x['product_id']),\n",
        "    'age': x['age'],\n",
        "    'search_query': x['search_query']\n",
        "})\n",
        "\n",
        "ds_products = tf.data.Dataset.from_tensor_slices(dict(df_products))\n",
        "ds_products = ds_products.batch(32).map(lambda x: tf.strings.as_string(x['product_id']))\n",
        "\n",
        "# Get all the user IDs\n",
        "user_ids = ds_ecommerce.batch(1000000).map(lambda x: x[\"user_id\"])\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids))).astype(str)\n",
        "\n",
        "# Get all the product IDs\n",
        "product_ids = ds_ecommerce.batch(1000000).map(lambda x: x[\"product_id\"])\n",
        "unique_product_ids = np.unique(np.concatenate(list(product_ids))).astype(str)"
      ],
      "metadata": {
        "id": "z-5OQB4P1M1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9414d71-18be-460f-a67a-2d265988de88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_products = tf.data.Dataset.from_tensor_slices(dict(df_products))\n",
        "ds_products = ds_products.batch(500).map(lambda x: tf.strings.as_string(x['product_id']))"
      ],
      "metadata": {
        "id": "ZO03dJEOIeTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 01 - Two-Towers (IDs Only)"
      ],
      "metadata": {
        "id": "Yn_gPEEjkJMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User and Product models.\n",
        "class UserModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, unique_user_ids):\n",
        "    super().__init__()\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.user_embedding(inputs)\n",
        "\n",
        "class ProductModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, unique_product_ids):\n",
        "    super().__init__()\n",
        "\n",
        "    self.product_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_product_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_product_ids) + 1, 32)\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.product_embedding(inputs)\n",
        "\n",
        "# Define the two-tower model.\n",
        "class TwoTowerModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, user_model, product_model, task):\n",
        "    super().__init__()\n",
        "    self.user_model = user_model\n",
        "    self.product_model = product_model\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    positive_product_embeddings = self.product_model(features[\"product_id\"])\n",
        "\n",
        "    return self.task(user_embeddings, positive_product_embeddings)\n",
        "\n",
        "# Instantiate and compile the model.\n",
        "user_model = UserModel(unique_user_ids)\n",
        "product_model = ProductModel(unique_product_ids)\n",
        "\n",
        "# Calculate embeddings for all products.\n",
        "product_embeddings = tf.data.Dataset.from_tensor_slices(unique_product_ids).batch(128).map(product_model)\n",
        "\n",
        "# Specify the task.\n",
        "task = tfrs.tasks.Retrieval(\n",
        "    metrics=tfrs.metrics.FactorizedTopK(candidates=product_embeddings)\n",
        ")\n",
        "\n",
        "model = TwoTowerModel(user_model, product_model, task)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "htO5820j1ON9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 3 epochs.\n",
        "model.fit(ds_ecommerce.batch(1000), epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncATfK3F25tJ",
        "outputId": "81b9220c-0a73-493f-9cba-1e9b34f43e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 170ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0012 - factorized_top_k/top_10_categorical_accuracy: 0.0024 - factorized_top_k/top_50_categorical_accuracy: 0.0152 - factorized_top_k/top_100_categorical_accuracy: 0.0325 - loss: 6907.8219 - regularization_loss: 0.0000e+00 - total_loss: 6907.8219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4359b0e8c0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = 3\n",
        "\n",
        "# Use brute-force search to set up retrieval using the trained representations.\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=K)\n",
        "\n",
        "# Populate the index with the embeddings from the product model. And, perform this\n",
        "# operation in batch with a size of 32 observations for efficiency.\n",
        "product_embeddings_to_index = ds_products.map(lambda id: model.product_model(id))\n",
        "index.index_from_dataset(product_embeddings_to_index)\n",
        "\n",
        "# # Get some recommendations.\n",
        "user_id = \"1\"\n",
        "_, products = index(np.array([user_id]))\n",
        "print(f\"Top 3 recommendations for user {user_id}: {products[0, :K]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HCjAD1nmxwW",
        "outputId": "5d7ab335-ae61-4a86-8406-133988bfb14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommendations for user 1: [1116   11 1199]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 02 - Two-Towers w/ Meta Data"
      ],
      "metadata": {
        "id": "vOPScYBQqfsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User and Product models.\n",
        "class ProductModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, unique_product_ids):\n",
        "    super().__init__()\n",
        "\n",
        "    self.product_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_product_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_product_ids) + 1, 32)\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.product_embedding(inputs)\n",
        "\n",
        "class UserModelMetaData(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, unique_user_id_list):\n",
        "    super().__init__()\n",
        "\n",
        "    # User ID Embedding\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_user_id_list, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_id_list) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    # User age\n",
        "    self.age_normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=None)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    user_emb = self.user_embedding(inputs['user_id'])\n",
        "    age = self.age_normalizer(inputs['age'])\n",
        "    return tf.concat([user_emb, tf.reshape(age, (-1, 1))], axis=1)\n",
        "\n",
        "  def adapt(self, data):\n",
        "    age_data = data.map(lambda x: x['age'])\n",
        "    self.age_normalizer.adapt(age_data)\n",
        "\n",
        "# Define the two-tower model.\n",
        "class TwoTowerModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, user_model, product_model, task):\n",
        "    super().__init__()\n",
        "    self.user_model = tf.keras.Sequential([\n",
        "      user_model,\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.product_model = product_model\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    user_embeddings = self.user_model({\n",
        "        'user_id': features['user_id'],\n",
        "        'age': features['age']\n",
        "    })\n",
        "    positive_product_embeddings = self.product_model(features['product_id'])\n",
        "    return self.task(user_embeddings, positive_product_embeddings)\n",
        "\n",
        "# You need to gather the unique user ids and product ids to instantiate the models.\n",
        "user_ids = ds_ecommerce.batch(1000000).map(lambda x: x[\"user_id\"])\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids))).astype(str)\n",
        "\n",
        "# Get all the product IDs\n",
        "product_ids = ds_ecommerce.batch(1000000).map(lambda x: x[\"product_id\"])\n",
        "unique_product_ids = np.unique(np.concatenate(list(product_ids))).astype(str)\n",
        "\n",
        "# Instantiate and compile the model.\n",
        "user_model = UserModelMetaData(unique_user_ids)\n",
        "# user_model.adapt(ds_ecommerce)\n",
        "\n",
        "product_model = ProductModel(unique_product_ids)\n",
        "\n",
        "# Calculate embeddings for all products.\n",
        "product_embeddings = ds_products.map(product_model)\n",
        "\n",
        "# Specify the task.\n",
        "task = tfrs.tasks.Retrieval(\n",
        "    metrics=tfrs.metrics.FactorizedTopK(candidates=product_embeddings)\n",
        ")\n",
        "\n",
        "model = TwoTowerModel(user_model, product_model, task)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "VHh9MyHPqk92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 3 epochs.\n",
        "model.fit(ds_ecommerce.batch(1000), epochs=1)"
      ],
      "metadata": {
        "id": "_lfAl7y-NW7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6614141e-e141-426b-8005-aeaab6f38309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>, 'age': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 128ms/step - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0011 - factorized_top_k/top_10_categorical_accuracy: 0.0015 - factorized_top_k/top_50_categorical_accuracy: 0.0070 - factorized_top_k/top_100_categorical_accuracy: 0.0132 - loss: 8886.6837 - regularization_loss: 0.0000e+00 - total_loss: 8886.6837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f42983e9f90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = 3\n",
        "\n",
        "# Get some recommendations.\n",
        "user_id = tf.constant([\"1\"])  # user_id should be a string tensor\n",
        "user_age = tf.constant([25])  # user_age should be a numeric tensor\n",
        "\n",
        "# Use brute-force search to set up retrieval using the trained representations.\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k=K)\n",
        "\n",
        "# Add candidates in the index\n",
        "product_embeddings_to_index = ds_products.map(lambda id: model.product_model(id))\n",
        "index.index_from_dataset(product_embeddings_to_index)\n",
        "\n",
        "# You need to pass the user_id and age in a dictionary.\n",
        "_, products = index({\"user_id\": user_id, \"age\": user_age})\n",
        "print(f\"Top 3 recommendations for user {user_id}: {products[0, :K]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft3hbjbQujqt",
        "outputId": "c61a5437-7569-4a25-948b-480b91694b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'1'], dtype=object)>, 'age': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([25], dtype=int32)>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommendations for user [b'1']: [1518 1256  890]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 03 - Two-Towers w/ Search Query"
      ],
      "metadata": {
        "id": "gQldOg6gkj8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User and Product models.\n",
        "class ProductModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, unique_product_ids):\n",
        "    super().__init__()\n",
        "\n",
        "    self.product_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_product_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_product_ids) + 1, 32)\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.product_embedding(inputs)\n",
        "\n",
        "class UserModelSearchData(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, unique_user_id_list, max_tokens=1000, output_sequence_length=30):\n",
        "    super().__init__()\n",
        "\n",
        "    # User ID Embedding\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "        vocabulary=unique_user_id_list, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_id_list) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    # User age\n",
        "    self.age_normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=None)\n",
        "\n",
        "    # Search Query Embedding\n",
        "    self.search_vectorization = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "        max_tokens=max_tokens, output_sequence_length=output_sequence_length)\n",
        "    self.search_embedding = tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    user_emb = self.user_embedding(inputs['user_id'])\n",
        "    age = self.age_normalizer(inputs['age'])\n",
        "\n",
        "    # Incorporate search history\n",
        "    search_seq = self.search_vectorization(inputs['search_query'])\n",
        "    search_emb = self.search_embedding(search_seq)\n",
        "    search_emb = tf.reduce_mean(search_emb, axis=1)\n",
        "\n",
        "    concatenated = tf.concat([user_emb, tf.reshape(age, (-1, 1)), search_emb], axis=1)\n",
        "    return self.dense(concatenated)\n",
        "\n",
        "  def adapt(self, data):\n",
        "    age_data = data.map(lambda x: x['age'])\n",
        "    self.age_normalizer.adapt(age_data)\n",
        "    search_data = data.map(lambda x: x['search_query'])\n",
        "    self.search_vectorization.adapt(search_data)\n",
        "\n",
        "\n",
        "# Define the two-tower model.\n",
        "class TwoTowerModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, user_model, product_model, task):\n",
        "    super().__init__()\n",
        "    self.user_model = user_model\n",
        "    self.product_model = product_model\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    user_embeddings = self.user_model(features)\n",
        "    positive_product_embeddings = self.product_model(features['product_id'])\n",
        "\n",
        "    return self.task(user_embeddings, positive_product_embeddings)\n",
        "\n",
        "# Instantiate and compile the model.\n",
        "user_model = UserModelSearchData(unique_user_ids)\n",
        "user_model.adapt(ds_ecommerce)\n",
        "\n",
        "product_model = ProductModel(unique_product_ids)\n",
        "\n",
        "# Calculate embeddings for all products.\n",
        "product_embeddings = ds_products.map(product_model)\n",
        "\n",
        "# Specify the task.\n",
        "task = tfrs.tasks.Retrieval(\n",
        "    metrics=tfrs.metrics.FactorizedTopK(candidates=product_embeddings)\n",
        ")\n",
        "\n",
        "model = TwoTowerModel(user_model, product_model, task)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "kVhlyrysX2Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 3 epochs.\n",
        "model.fit(ds_ecommerce.batch(1000), epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHovCysJfnZ7",
        "outputId": "f0dc1e99-162d-464d-dffa-342ba93a6dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 128ms/step - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 3.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0011 - factorized_top_k/top_50_categorical_accuracy: 0.0076 - factorized_top_k/top_100_categorical_accuracy: 0.0186 - loss: 6909.5461 - regularization_loss: 0.0000e+00 - total_loss: 6909.5461\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4298647190>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set how many nearest products to retrieve\n",
        "K = 3\n",
        "\n",
        "# Get some recommendations.\n",
        "user_id = tf.constant([\"1\"])  # user_id should be a string tensor\n",
        "user_age = tf.constant([25])  # user_age should be a numeric tensor\n",
        "user_search = tf.constant(['shirt'])\n",
        "user_query = {\"user_id\": user_id, \"age\": user_age, \"search_query\": user_search}\n",
        "\n",
        "# Use brute-force search to set up retrieval using the trained representations.\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "\n",
        "# Add candidates in the index\n",
        "product_embeddings_to_index = ds_products.map(lambda id: model.product_model(id))\n",
        "index.index_from_dataset(product_embeddings_to_index)\n",
        "\n",
        "# You need to pass the user_id and age in a dictionary.\n",
        "_, products = index(user_query, k=100)\n",
        "print(f\"Top {K} recommendations for user {user_id}: {products[0, :K]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh62IlxfvUOt",
        "outputId": "4ba53bcf-13ab-4e6c-8480-30d534db3e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user [b'1']: [2714 1219 1309 2425  377]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 04 - Fast Retrieval"
      ],
      "metadata": {
        "id": "oUrftzAYLbNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lots_of_embeddings = (\n",
        "    ds_products\n",
        "      .repeat(100)\n",
        "      .map(lambda id: model.product_model(id))\n",
        "      .map(lambda x: x * tf.random.uniform(tf.shape(x)))\n",
        ")"
      ],
      "metadata": {
        "id": "QAQAJRN-TlgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scann_index = tfrs.layers.factorized_top_k.ScaNN(\n",
        "    model.user_model,\n",
        "    # Number of leaves (clusters)\n",
        "    num_leaves=100,\n",
        "    # Top 10 clusters to search from the query to the centroid\n",
        "    num_leaves_to_search=10\n",
        ")\n",
        "\n",
        "# Add candidates in the index\n",
        "# product_embeddings_to_index = ds_products.map(lambda id: model.product_model(id))\n",
        "scann_index.index_from_dataset(lots_of_embeddings)\n",
        "\n",
        "# You need to pass the user_id and age in a dictionary.\n",
        "_, products = scann_index(user_query, k=100)\n",
        "print(f\"Top {K} recommendations for user {user_id}: {products[0, :K]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gB4l-57LfiF",
        "outputId": "fcda145a-cbfa-44cd-c258-938484d52bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user [b'1']: [  7219 187309 224714 131714 224425]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 1000 _, products = scann_index(user_query, k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3hUbaz_j_6j",
        "outputId": "d734b563-2c78-45cf-f1a3-fac38a286386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.36 ms ± 275 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tune ScaNN"
      ],
      "metadata": {
        "id": "UQIRLgurgFHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scann_index_v2 = tfrs.layers.factorized_top_k.ScaNN(\n",
        "    model.user_model,\n",
        "    # Number of leaves (clusters)\n",
        "    num_leaves=100,\n",
        "    # Top 3 clusters to search from the query to the centroid\n",
        "    num_leaves_to_search=3,\n",
        "    # Get top 100 candidates based on approximate distance,\n",
        "    # which uses the distance between the centroid and query to approximate\n",
        "    # the distance between query to neighbors. Then of those 100 candidates\n",
        "    # sort based on the exact distance between the query and neighbors.\n",
        "    # num_reordering_candidates=10\n",
        ")\n",
        "\n",
        "# Add candidates in the index\n",
        "# product_embeddings_to_index = ds_products.map(lambda id: model.product_model(id))\n",
        "scann_index_v2.index_from_dataset(lots_of_embeddings)\n",
        "\n",
        "# You need to pass the user_id and age in a dictionary.\n",
        "_, products = scann_index_v2(user_query, k=100)\n",
        "print(f\"Top {K} recommendations for user {user_id}: {products[0, :K]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lodEpQBbbYB",
        "outputId": "77d24e2d-0a5c-4e21-d84c-583bfa7064a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user [b'1']: [ 74714  47466 180490  92714 101466]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 1000 _, products = scann_index_v2(user_query, k=3)"
      ],
      "metadata": {
        "id": "GIusb1Y6kgE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}